# Haunt Framework White Paper

## Executive Summary

**Haunt** is a lightweight framework that transforms AI language models into coordinated development teams through external memory patterns, structured workflows, and enforced invariants. By combining project management (roadmap-driven development), external memory (rules, skills, agents), and cognitive architecture (layered context management), Haunt enables developers to collaborate with AI agents that maintain context across sessions, follow consistent methodologies, and produce production-quality software.

**What makes Haunt unique:** While traditional AI coding assistants provide one-off code generation, Haunt creates persistent agent personalities that remember your project's standards, coordinate parallel workstreams, and maintain quality through automated verificationâ€”all while keeping the human developer in the decision-making seat.

---

## Document Navigation

**If you want to:**
- **Understand the problem Haunt solves** â†’ Read "The Problem" and "Why Existing Approaches Fall Short"
- **Get a high-level overview** â†’ Read "Introduction: Haunt's Solution" and "Core Concepts"
- **Learn the architecture** â†’ Read "Architecture" section (four-layer system)
- **Start using Haunt immediately** â†’ Jump to "Getting Started" and "Your First Project"
- **Understand key workflows** â†’ Read "Key Workflows" (Session Startup, SÃ©ance, Daily Rituals)
- **See implementation specifics** â†’ Read "Implementation Details" (Roadmap, Commits, Testing)
- **Quick reference** â†’ Jump to "Appendix: Quick Reference" at the end

**Recommended reading paths:**
- **New users**: Executive Summary â†’ Getting Started â†’ Your First Project â†’ Core Concepts
- **Architects/Leads**: The Problem â†’ Architecture â†’ Key Workflows â†’ Implementation Details
- **Existing users**: Jump to specific sections as needed, use Appendix for quick reference

---

## The Problem

### The Coordination Challenge

AI language models have demonstrated remarkable ability to write code, but building complex software requires more than isolated code generation:

1. **Context Loss Across Sessions**
   - LLMs are stateless; each conversation starts fresh
   - Previous architectural decisions are forgotten
   - Team conventions reset with every new chat
   - No memory of what was tried and failed

2. **Lack of Consistent Process**
   - Different prompts produce wildly different approaches
   - No enforcement of testing standards
   - Commit messages vary in quality
   - Requirements drift mid-implementation

3. **Multi-Agent Coordination Problems**
   - How do multiple AI agents work on the same codebase?
   - Who decides priorities when agents have conflicting tasks?
   - How do you prevent duplicate work or merge conflicts?
   - What happens when one agent's work blocks another?

4. **Quality Control**
   - No systematic review before merging
   - Tests written inconsistently (or not at all)
   - Technical debt accumulates silently
   - Anti-patterns spread across the codebase

### Why Existing Approaches Fall Short

**One-Shot Code Generation Tools:**
- Generate code without understanding project context
- No memory of previous conversations or decisions
- Cannot coordinate with other agents
- No enforcement of team standards

**Agent Frameworks Without Process:**
- Provide coordination but not methodology
- Leave quality standards to human discretion
- Lack enforcement mechanisms for best practices
- No built-in project management workflow

**IDE Plugins:**
- Excellent for autocomplete, poor for architecture
- Cannot manage multi-file features
- No cross-session memory
- Limited to single-developer workflows

---

## Introduction: Haunt's Solution

Haunt solves these problems by treating AI agents as **specialized team members with external memory**. Instead of monolithic "do everything" assistants, Haunt provides:

1. **Agent Specialization** - Distinct roles (Dev, PM, Researcher, Code Reviewer) with clear responsibilities
2. **External Memory System** - Rules (always-on invariants), Skills (on-demand workflows), Roadmap (working memory)
3. **Project Management Integration** - Roadmap-driven development with status tracking and dependency management
4. **Quality Enforcement** - Automated checklists, pattern detection, and verification gates

The result: AI agents that behave like experienced team members who remember your project's conventions, coordinate their work, and maintain quality standardsâ€”all while staying under your control.

---

## Core Concepts

### 1. Haunt as a Project Management System

At its heart, Haunt is a **roadmap-driven development framework** that tracks work through a structured lifecycle:

#### Roadmap Structure

**Location:** `.haunt/plans/roadmap.md`

Every project has a single source of truth containing:
- **Active requirements** with status tracking (âšª Not Started, ðŸŸ¡ In Progress, ðŸŸ¢ Complete, ðŸ”´ Blocked)
- **Agent assignments** mapping work to specialized agents
- **Dependency chains** ensuring work happens in the correct order
- **Batch organization** enabling parallel execution

**Example Requirement:**
```markdown
### ðŸŸ¡ REQ-042: Implement user authentication endpoints

**Type:** Enhancement
**Reported:** 2025-01-15
**Source:** User story - secure API access

**Description:**
Create REST endpoints for user registration, login, and token refresh
with JWT-based authentication.

**Tasks:**
- [x] Create POST /auth/register endpoint
- [x] Create POST /auth/login endpoint
- [ ] Create POST /auth/refresh endpoint
- [ ] Add rate limiting to auth endpoints

**Files:**
- `src/api/auth.py` (create)
- `tests/test_auth.py` (create)

**Effort:** M
**Complexity:** MODERATE
**Agent:** Dev-Backend
**Completion:** All endpoints return correct status codes, tests pass, rate limiting verified
**Blocked by:** None
```

#### Status Icon System

| Icon | Status | Meaning |
|------|--------|---------|
| âšª | Not Started | Ready to begin (dependencies met) |
| ðŸŸ¡ | In Progress | Agent actively working |
| ðŸŸ¢ | Complete | All criteria met, tests passing |
| ðŸ”´ | Blocked | Cannot proceed until dependency resolves |

Status updates flow automatically:
- **Worker agents** update roadmap status as they work
- **Project Manager** archives completed work and unblocks dependencies
- **Everyone** sees current state without asking

#### Effort and Complexity Indicators

Requirements are sized using **two independent dimensions**:

**Effort (Time/Scope):**
| Size | Time | Files | Lines Changed | When to Use |
|------|------|-------|---------------|-------------|
| **XS** | 30min-1hr | 1-2 files | <50 lines | Quick fixes, config changes |
| **S** | 1-2 hours | 2-4 files | 50-150 lines | Single component features, isolated bugs |
| **M** | 2-4 hours | 4-8 files | 150-300 lines | Multi-component features, moderate refactoring |
| **SPLIT** | >4 hours | >8 files | >300 lines | Must decompose into smaller requirements |

**Complexity (Cognitive Difficulty):**
| Level | Definition | Characteristics |
|-------|------------|-----------------|
| **SIMPLE** | Clear requirements, single pattern | Obvious implementation, no unknowns |
| **MODERATE** | Some investigation needed | 2-3 patterns, bounded unknowns |
| **COMPLEX** | Significant unknowns | Cross-cutting concerns, architectural decisions |
| **UNKNOWN** | Cannot estimate | Needs research spike first |

**Why separate dimensions?**
- A quick fix can be **XS effort** but **COMPLEX** (hard-to-diagnose race condition)
- A large feature can be **M effort** but **SIMPLE** (straightforward CRUD endpoint)
- Helps agents estimate both time commitment and cognitive load

#### Batch Organization for Parallelization

Related requirements are organized into batches:

```markdown
## Batch 1: Foundation (can run in parallel)

### âšª REQ-001: Set up database schema
**Agent:** Dev-Backend

### âšª REQ-002: Create React app structure
**Agent:** Dev-Frontend

## Batch 2: Features (blocked by Batch 1)

### âšª REQ-003: User management API
**Agent:** Dev-Backend
**Blocked by:** REQ-001

### âšª REQ-004: User management UI
**Agent:** Dev-Frontend
**Blocked by:** REQ-002, REQ-003
```

**Benefits:**
- REQ-001 and REQ-002 can run simultaneously (different agents, no conflicts)
- REQ-003 waits until database schema exists
- REQ-004 waits for both backend and frontend foundations
- PM tracks batch completion and unblocks next phase automatically

#### Completion Verification

Before marking any requirement ðŸŸ¢, agents verify:
1. âœ… All task checkboxes marked `[x]`
2. âœ… Completion criteria met
3. âœ… Tests passing (appropriate test command for work type)
4. âœ… Files modified as specified
5. âœ… Documentation updated (if applicable)
6. âœ… Security review completed (if code involves user input, auth, database queries, external APIs, file operations, or dependencies)
7. âœ… Self-validation performed (re-read requirement, review own code, confirm tests actually test the feature, check against known anti-patterns)

No shortcuts. No "I'll test it later." Quality is enforced through systematic verification at every stage.

#### Roadmap Sharding for Large Projects

For projects with many requirements, roadmaps can be **sharded into batch files** to reduce context size and improve agent performance:

**Monolithic roadmap** (default):
```
.haunt/plans/roadmap.md  â† All requirements in one file
```

**Sharded roadmap** (optimization):
```
.haunt/plans/roadmap.md           â† Overview + active batch only
.haunt/plans/batches/
  â”œâ”€â”€ batch-1-foundation.md       â† Batch 1 requirements
  â”œâ”€â”€ batch-2-features.md         â† Batch 2 requirements
  â””â”€â”€ batch-3-polish.md           â† Batch 3 requirements
```

**How it works:**
- `roadmap.md` contains project overview and the currently active batch
- Completed batches move to `.haunt/plans/batches/` for archival reference
- Agents only load the active batch context, reducing token usage
- Assignment lookup checks for sharded structure and loads appropriate batch file

**When to shard:**
- Roadmap exceeds 500 lines (readability limit)
- More than 20-30 active requirements
- Multi-phase projects with clear batch boundaries
- Performance optimization needed

**Benefits:**
- Faster agent startup (less context to load)
- Better focus (agents see only relevant work)
- Easier navigation (batches are self-contained)
- Preserves history (completed batches archived, not deleted)

---

### 2. Haunt as an External Memory Framework

LLMs are stateless, but software development requires institutional memory. Haunt provides a **layered memory hierarchy** that gives agents persistent knowledge:

#### Memory Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: RULES (Always-On Invariant Memory)    â”‚ â† Auto-loaded every session
â”‚ - Session startup protocol                      â”‚   Enforced as constraints
â”‚ - Commit conventions                            â”‚
â”‚ - File location rules                           â”‚
â”‚ - Status update protocol                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 2: AGENTS (Identity Memory)              â”‚ â† Loaded on agent spawn
â”‚ - "I am a Dev agent"                            â”‚   Character sheet
â”‚ - Values, modes, responsibilities              â”‚
â”‚ - Tool permissions                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 3: SKILLS (Procedural Memory)            â”‚ â† Loaded on-demand
â”‚ - "How to write a commit message"              â”‚   Workflow instructions
â”‚ - "How to run TDD workflow"                     â”‚
â”‚ - "How to organize roadmap batches"            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 4: CLAUDE.md (Project Context Memory)    â”‚ â† Always loaded
â”‚ - Repository purpose                            â”‚   Project-specific
â”‚ - Current active work                           â”‚
â”‚ - Key automation scripts                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 5: ROADMAP (Working Memory)              â”‚ â† Checked at startup
â”‚ - Current requirements                          â”‚   Task-level detail
â”‚ - Task checklists                               â”‚
â”‚ - Agent assignments                             â”‚
â”‚ - Completion criteria                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### How Each Layer Works

**Layer 1: Rules (Invariant Memory)**

Rules are markdown files in `.claude/rules/` that **auto-load and enforce protocols**.

Example: `gco-session-startup.md`
```markdown
# Session Startup Protocol

Execute in order, every session, before ANY work:

1. Verify Environment: `pwd && git status`
2. Check Recent Changes: `git log --oneline -5`
3. Verify Tests Pass: `pytest tests/ -x -q`
4. Find Your Assignment: Check Active Work â†’ Roadmap â†’ Ask PM
```

**What this achieves:**
- Agents always start sessions the same way (no forgetting to verify tests)
- Protocols are **enforced**, not suggested
- Updates propagate to all agents instantly (single source of truth)

**Layer 2: Agents (Identity Memory)**

Lightweight character sheets (30-50 lines) defining WHO the agent is:

```markdown
---
name: gco-dev
tools: Read, Write, Bash, Grep, Glob, mcp__context7__*
skills: gco-tdd-workflow, gco-commit-conventions
---

# Dev Agent

## Identity
I am a Dev agent. I implement features, write tests, and maintain
code quality across backend, frontend, and infrastructure modes.

## Values
- Tests before implementation
- Explicit over implicit
- Simple over clever
```

**What this achieves:**
- Consistent personality across sessions
- Clear tool permissions (Dev can run Bash, PM cannot)
- References skills instead of duplicating workflows (DRY for agents)

**Layer 3: Skills (Procedural Memory)**

Reusable workflows loaded on-demand when agents need specific guidance:

```markdown
---
name: gco-tdd-workflow
description: Red-Green-Refactor cycle for test-driven development
---

# TDD Workflow

## Red Phase: Write Failing Test
1. Understand requirement from roadmap
2. Write test that would pass if feature existed
3. Run test suite, verify new test fails
...
```

**What this achieves:**
- Skills shared across all agents (update once, all agents benefit)
- On-demand loading (skills only loaded when invoked, saving tokens)
- Version control for methodology (track workflow changes over time)

**Layer 4: CLAUDE.md (Project Context)**

Project-specific context, always loaded:
- Repository structure
- Active work summary (PM maintains this)
- Setup commands
- Tech stack

**Layer 5: Roadmap (Working Memory)**

The detailed task list agents check at session start:
- Full requirement specifications
- Task-level checklists
- Completion criteria
- Blocking dependencies

---

### 3. Agent Coordination Through Role Specialization

Rather than one omnipotent agent, Haunt uses **specialized agents with clear boundaries**:

#### Agent Roles

| Agent | Role | Tools | Responsibilities |
|-------|------|-------|------------------|
| **Project-Manager** | Coordinator | Read, Write, Grep, Glob | Roadmap maintenance, requirements analysis, batch coordination, archiving |
| **Dev** | Implementation | Read, Write, Bash, Grep, Glob, mcp__context7__* | Write code, tests, commits; adapts to Backend/Frontend/Infrastructure modes |
| **Research** | Investigation | Read, Write, WebSearch, WebFetch, mcp__context7__* | Technical research, library investigation, documentation validation |
| **Code-Reviewer** | Quality Gate | Read, Write, Grep, Glob | PR review, pattern detection, merge coordination |
| **Release-Manager** | Deployment | Read, Write, Bash, Grep, Glob | Release coordination, changelog generation, deployment orchestration |

#### Coordination Pattern: "The SÃ©ance"

Haunt's parallel agent execution pattern:

```
User: "I want to build a task management app"
   â†“
Project Manager spawns
   â†“
Creates roadmap with requirements REQ-001 through REQ-010
   â†“
Batch 1: Foundation (parallel)
   â”œâ”€â”€ Dev-Backend: REQ-001 (database schema)
   â”œâ”€â”€ Dev-Frontend: REQ-002 (React app structure)
   â””â”€â”€ Dev-Infrastructure: REQ-003 (CI/CD pipeline)
   â†“
Batch 2: Features (sequential, after Batch 1)
   â”œâ”€â”€ Dev-Backend: REQ-004 (task CRUD API)
   â””â”€â”€ Dev-Frontend: REQ-005 (task list UI)
   â†“
Code-Reviewer: Review all PRs
   â†“
Release-Manager: Deploy to staging
```

**Key insight:** Agents don't talk to each other directly. The **roadmap is the communication layer**. Status updates, implementation notes, and blocking dependencies all flow through the roadmap, eliminating coordination overhead.

---

## Architecture

### The Four-Layer System

Haunt's architecture is organized into four distinct layers:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: AGENTS                              â”‚ â† WHO you are
â”‚   Character sheets (identity, values, mode)  â”‚   30-50 lines each
â”‚   Tool permissions                           â”‚
â”‚   Skill references                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 2: RULES                               â”‚ â† You MUST do this
â”‚   Invariant enforcement protocols            â”‚   Auto-loaded
â”‚   Non-negotiable constraints                 â”‚   50-100 lines each
â”‚   Session startup, commit format, status     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 3: SKILLS                              â”‚ â† HOW to do this
â”‚   Reusable workflows and procedures          â”‚   On-demand loading
â”‚   TDD, code review, roadmap management       â”‚   100-500 lines each
â”‚   Methodology guidance                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 4: COMMANDS                            â”‚ â† Shortcuts
â”‚   Common task automation                     â”‚   User-invoked
â”‚   Archival, validation, reporting            â”‚   Scripts + docs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Why This Layering Matters

**Agents are lightweight** because they reference skills rather than duplicating workflows.

**Rules are always on** because they enforce invariants that must never be violated (e.g., "always verify tests before starting work").

**Skills are on-demand** because they're detailed procedural guidance only needed in specific contexts (e.g., "how to conduct a strategic requirements analysis").

**Commands are shortcuts** because they automate repetitive tasks users would otherwise type manually.

---

### GCO Namespace Isolation

All Haunt framework assets use the `gco-*` prefix ("Ghost County" namespace):

- Agents: `gco-dev.md`, `gco-project-manager.md`
- Skills: `gco-session-startup/`, `gco-tdd-workflow/`
- Rules: `gco-commit-conventions.md`, `gco-roadmap-format.md`

**Why namespace isolation?**
- Prevents collisions with project-specific agents or skills
- Clearly identifies framework components vs. custom extensions
- Enables side-by-side deployment of multiple frameworks

---

### Deployment Model: Source â†’ Deployment

Haunt follows a **deploy-from-source** architecture:

```
Haunt/ (Source - Version Controlled)
  â”œâ”€â”€ agents/          â† Edit here
  â”‚   â”œâ”€â”€ gco-dev.md
  â”‚   â”œâ”€â”€ gco-project-manager.md
  â”‚   â””â”€â”€ ...
  â”œâ”€â”€ rules/           â† Edit here
  â”‚   â”œâ”€â”€ gco-session-startup.md
  â”‚   â””â”€â”€ ...
  â”œâ”€â”€ skills/          â† Edit here
  â”‚   â”œâ”€â”€ gco-tdd-workflow/
  â”‚   â””â”€â”€ ...
  â””â”€â”€ scripts/
      â””â”€â”€ setup-haunt.sh  â† Deployment script
         â†“
~/.claude/ (Global Deployment - User Home)
  â”œâ”€â”€ agents/          â† Copied from Haunt/agents/
  â”œâ”€â”€ rules/           â† Copied from Haunt/rules/
  â””â”€â”€ skills/          â† Copied from Haunt/skills/
         â†“
.claude/ (Project Deployment - Project Root)
  â”œâ”€â”€ agents/          â† Optional overrides
  â””â”€â”€ rules/           â† Optional overrides
```

**Critical principle:** ALWAYS edit source files in `Haunt/`, then deploy. Editing deployed copies (`~/.claude/`) leads to inconsistency when setup script runs again.

**Deployment commands:**
```bash
# Full setup (global + project)
bash Haunt/scripts/setup-haunt.sh

# Update only global agents
bash Haunt/scripts/setup-haunt.sh --agents-only

# Setup only project structure (skip global agents)
bash Haunt/scripts/setup-haunt.sh --project-only

# Verify installation
bash Haunt/scripts/setup-haunt.sh --verify
```

---

### Wrapper Scripts: Structured Execution Layer

Haunt provides **structured wrapper scripts** that return JSON for programmatic verification and eliminate token-wasting manual file parsing.

**Why Wrappers Matter:**

Traditional workflow (token-intensive):
```bash
# Agent reads entire 1647-line roadmap to find one requirement
Read(.haunt/plans/roadmap.md)  # 1647 lines = ~4000 tokens

# Agent runs tests manually, parses output
pytest tests/ -v  # Parses human-readable output
```

Wrapper workflow (token-efficient):
```bash
# Get specific requirement as JSON
bash Haunt/scripts/haunt-roadmap.sh get REQ-XXX  # Returns ~30 lines JSON

# Run tests with structured output
bash Haunt/scripts/haunt-run.sh test  # Returns JSON with pass/fail/coverage
```

**Token savings:** 60-98% reduction for common operations.

#### Available Wrapper Scripts

| Script | Purpose | Output Format |
|--------|---------|---------------|
| `haunt-roadmap.sh` | Structured roadmap lookup | JSON (requirement details) |
| `haunt-run.sh` | Build/test/lint execution | JSON (results, coverage, failures) |
| `haunt-verify.sh` | Completion criteria verification | JSON (pass/fail per criterion) |
| `haunt-archive.sh` | Archive completed requirements | JSON (archival confirmation) |
| `haunt-read.sh` | Smart file reader with caching | Cached content or file path |
| `haunt-story.sh` | Story file management | JSON (story context, session notes) |
| `haunt-lessons.sh` | Lessons-learned query | Relevant lessons for requirement |
| `haunt-metrics.sh` | Performance metrics collection | JSON (execution time, token usage) |
| `haunt-git.sh` | Git operation wrappers | JSON (commit info, status) |

#### Example: Structured Roadmap Lookup

**Without wrapper (traditional):**
```bash
# Dev agent needs REQ-042 details
Read(.haunt/plans/roadmap.md)  # 1647 lines
grep -A 30 "REQ-042" .haunt/plans/roadmap.md  # Manual parsing
```

**With wrapper (optimized):**
```bash
# Get structured JSON output
$ bash Haunt/scripts/haunt-roadmap.sh get REQ-042

{
  "id": "REQ-042",
  "title": "Implement user authentication endpoints",
  "status": "ðŸŸ¡",
  "agent": "Dev-Backend",
  "effort": "M",
  "complexity": "MODERATE",
  "tasks": [
    {"text": "Create POST /auth/register", "done": true},
    {"text": "Create POST /auth/login", "done": true},
    {"text": "Add rate limiting", "done": false}
  ],
  "blocked_by": "None"
}
```

**Result:** Agent gets exactly what it needs in 30 lines instead of reading 1647.

#### Example: Structured Test Execution

**Without wrapper:**
```bash
# Run tests, parse human-readable output
pytest tests/ -v

# Agent manually parses:
# "test_auth.py::test_register PASSED [10%]"
# "test_auth.py::test_login PASSED [20%]"
# ... 100+ lines of output ...
```

**With wrapper:**
```bash
$ bash Haunt/scripts/haunt-run.sh test

{
  "success": true,
  "framework": "pytest",
  "passed": 23,
  "failed": 0,
  "skipped": 1,
  "duration_seconds": 4.2,
  "coverage_percent": 87.3,
  "failures": []
}
```

**Result:** Structured output for programmatic verification, no manual parsing.

#### Example: Completion Verification

**Without wrapper:**
```bash
# Agent manually checks each criterion:
# 1. Read roadmap, count checkboxes
# 2. Run pytest, check exit code
# 3. Run coverage, parse output
# 4. Check file existence
# 5. Verify commit format
# ... 30+ commands, 5000+ tokens ...
```

**With wrapper:**
```bash
$ bash Haunt/scripts/haunt-verify.sh REQ-042 backend

{
  "success": true,
  "requirement": "REQ-042",
  "summary": "5/5 criteria passed",
  "criteria": [
    {"name": "tasks_complete", "status": "PASS", "evidence": "3/3 tasks checked"},
    {"name": "files_exist", "status": "PASS", "evidence": "All 2 files exist"},
    {"name": "tests_pass", "status": "PASS", "evidence": "23/23 tests passed"},
    {"name": "coverage", "status": "PASS", "evidence": "87% coverage"},
    {"name": "commits_valid", "status": "PASS", "evidence": "3 commits follow convention"}
  ]
}
```

**Result:** One command verifies ALL completion criteria programmatically.

---

### Metrics Framework: Zero Agent Overhead

Haunt includes a **lightweight metrics collection system** that tracks framework performance without requiring agent awareness or manual instrumentation.

**Design principle:** Metrics collection happens **outside agent context**â€”wrapper scripts emit metrics, agents remain unaware.

#### How It Works

**Traditional metrics (problematic):**
```python
# Agent must manually track metrics (adds complexity)
start_time = time.time()
result = implement_feature()
metrics.record("feature_time", time.time() - start_time)
```

**Haunt metrics (transparent):**
```bash
# Wrapper script handles metrics automatically
$ bash Haunt/scripts/haunt-run.sh test

# Emits metrics to .haunt/metrics/metrics.jsonl:
{"timestamp": "2025-12-31T10:30:00Z", "operation": "test", "duration_seconds": 4.2, "success": true}

# Agent sees only the test result (no metrics awareness needed)
```

#### What Gets Tracked

| Metric | Source | Purpose |
|--------|--------|---------|
| Test execution time | `haunt-run.sh test` | Performance regression detection |
| Build time | `haunt-run.sh build` | Build optimization opportunities |
| Requirement completion time | `haunt-verify.sh` | Effort estimation calibration |
| Token usage per operation | `haunt-read.sh`, `haunt-roadmap.sh` | Optimization validation |
| Wrapper script usage | All wrapper scripts | Adoption tracking |

#### Metrics Output Format

**File:** `.haunt/metrics/metrics.jsonl` (JSON Lines format)

```json
{"timestamp": "2025-12-31T10:15:00Z", "operation": "test", "framework": "pytest", "passed": 23, "failed": 0, "duration_seconds": 4.2, "coverage_percent": 87.3}
{"timestamp": "2025-12-31T10:20:00Z", "operation": "roadmap_lookup", "requirement": "REQ-042", "token_savings": 4100, "duration_ms": 45}
{"timestamp": "2025-12-31T10:25:00Z", "operation": "verify_completion", "requirement": "REQ-042", "criteria_passed": 5, "criteria_failed": 0}
```

#### Analysis and Reporting

```bash
# Generate summary report
$ bash Haunt/scripts/haunt-metrics.sh report --last-week

Framework Performance (Last 7 Days):
- Average test execution: 4.3s
- Average token savings per lookup: 3,800 tokens
- Requirements completed: 12
- Wrapper script adoption: 89%

Top optimization opportunities:
1. Test execution +15% slower than baseline
2. Coverage dropped from 91% to 87%
3. REQ-042 took 3.2hr (estimated 2hr) - calibrate estimates
```

**Key insight:** Metrics inform framework improvements without burdening agents with instrumentation logic.

---

### Skill Refactoring Pattern: Reference Files + Consultation Gates

To prevent token bloat in rules while maintaining comprehensive guidance, Haunt uses a **two-tier skill architecture**:

**Tier 1: Slim Reference Files (Rules)**
- Auto-loaded every session (~50-100 lines)
- Core protocols and non-negotiable requirements
- Summary checklists with "invoke full skill" gates

**Tier 2: Comprehensive Skills (On-Demand)**
- Loaded only when invoked (~300-600 lines)
- Detailed examples, edge cases, anti-patterns
- Complete methodology and best practices

#### Example: Completion Checklist

**Before refactoring** (rule file bloated):
```markdown
# gco-completion-checklist.md (800 lines - auto-loaded!)
- Complete checklist with ALL details
- Detailed examples for each step
- Anti-patterns to avoid
- Edge case handling
- Integration with other workflows
- ... 700 more lines ...
```

**Token cost:** 800 lines Ã— ~2.5 tokens/line = **2,000 tokens per session**

**After refactoring** (slim reference + consultation gate):

**Tier 1: Slim Reference (Rule)** - `gco-completion-checklist.md` (~100 lines)
```markdown
# Completion Checklist (Slim Reference)

## Before Marking ANY Requirement ðŸŸ¢

Run through this checklist:

1. All Tasks Checked Off
2. Completion Criteria Met
3. Tests Passing (non-negotiable)
4. Files Updated
5. ...

## When to Invoke Full Skill

For detailed requirements, checklists for each step, examples, and anti-patterns:

**Invoke:** `/gco-completion` skill

The skill contains:
- Detailed verification requirements for each step
- Testing requirements by agent type
- Iterative refinement checklist
- Anti-patterns to avoid with examples
```

**Tier 2: Comprehensive Skill (On-Demand)** - `gco-completion/SKILL.md` (~600 lines)
```markdown
# Completion Checklist: Comprehensive Guide

## Purpose
Detailed verification workflow for marking requirements complete...

[Full 600 lines of examples, anti-patterns, edge cases, etc.]
```

**Token savings:** 1,900 tokens saved per session (agents only load 100-line reference unless they need details).

#### When to Use Consultation Gates

Add consultation gates when:
- Rule file exceeds 200 lines
- Content includes many examples or edge cases
- Guidance is context-specific (not needed every session)
- Methodology changes frequently (easier to update skill than rule)

**Pattern:**
1. Identify bloated rule file (>200 lines)
2. Extract detailed content to skill
3. Leave slim checklist in rule with "Invoke skill for details"
4. Agents load skill on-demand when they need comprehensive guidance

**Result:** Rules stay lightweight (auto-loaded), skills provide depth (on-demand).

---

### 1. Session Startup Protocol

**Every agent, every session, follows this checklist:**

```bash
# Step 1: Verify Environment
pwd && git status
# Check working directory, uncommitted changes

# Step 2: Check Recent Changes
git log --oneline -5
# Understand what was recently completed

# Step 3: Verify Tests Pass
pytest tests/ -x -q  # (or npm test, depending on mode)
# CRITICAL: Fix broken tests BEFORE starting new work

# Step 4: Find Your Assignment
# Priority 1: Direct user assignment ("implement REQ-042")
# Priority 2: CLAUDE.md Active Work section
# Priority 3: .haunt/plans/roadmap.md (âšª or ðŸŸ¡ for my agent type)
# Priority 4: Ask PM if nothing found
```

**Why this matters:**
- Prevents starting work on broken foundation
- Ensures agent knows git state before making changes
- Eliminates "what should I work on?" ambiguity
- Creates consistent behavior across all agents

---

### 2. The "SÃ©ance" (Complete Development Ritual)

The SÃ©ance is Haunt's complete idea-to-shipped workflow - a guided ritual that handles planning, execution, and archival with zero manual coordination.

**The Three-Part Ritual:**
```
ðŸ”® Scrying   (Planning)   â†’ /seance --scry    or --plan
ðŸ‘» Summoning (Execution)  â†’ /seance --summon  or --execute
âš°ï¸ Banishing (Archival)   â†’ /seance --banish  or --archive
```

**Quick Example:**
```bash
# One command: idea â†’ shipped feature
$ /seance "Add OAuth login support"

ðŸ”® Scrying... (creates formal requirements, strategic analysis, roadmap)
ðŸ‘» Summoning... (spawns agents, implements features, runs tests)
âš°ï¸ Banishing... (archives completed work, cleans roadmap)

âœ… OAuth login shipped, tested, committed, documented, archived
```

**Key Features:**
- **Planning depth modes**: `--quick` (basic), default (standard), `--deep` (comprehensive JTBD/Kano/RICE analysis)
- **Parallel execution**: Agents work on independent requirements simultaneously
- **Automatic archival**: Completed work moves to `.haunt/completed/` automatically
- **Roadmap sharding**: Large projects split into batch files for performance
- **Phase gates**: Deterministic workflow with explicit pass/fail criteria at each phase transition

**Phase Gate Integration:**

Each SÃ©ance phase includes verification gates to ensure deterministic progression:

**Scrying Phase Gate:**
- âœ… Requirements document created with clear acceptance criteria
- âœ… Strategic analysis completed (or skipped if --quick)
- âœ… Roadmap updated with sized, assigned requirements
- âœ… No SPLIT-sized requirements (all decomposed to M or smaller)
- â›” FAIL: Blocks execution until requirements properly defined

**Summoning Phase Gate:**
- âœ… All tests passing before starting new work
- âœ… Git working directory clean or WIP properly committed
- âœ… Agent assignments clear and unambiguous
- âœ… Dependencies resolved (no ðŸ”´ blocked requirements in batch)
- â›” FAIL: Cannot spawn agents until foundation stable

**Banishing Phase Gate:**
- âœ… All requirements in batch marked ðŸŸ¢
- âœ… All task checkboxes checked
- âœ… All commits follow convention
- âœ… Documentation updated
- â›” FAIL: Cannot archive incomplete work

**Why it matters:**
- Say what you want (one line) â†’ come back to shipped features
- Zero coordination overhead (roadmap is the communication layer)
- Full SDLC automation from idea to production
- Deterministic workflow prevents premature phase transitions

**ðŸ“– For complete SÃ©ance documentation**, including:
- All 6 operating modes (interactive, direct, explicit phases)
- Planning depth levels (quick/medium/deep)
- Phase gate details and failure recovery
- Complete workflow examples (OAuth login walkthrough)
- Advanced usage (batch execution, roadmap sharding)
- Troubleshooting and best practices

**See:** `Haunt/docs/SEANCE-EXPLAINED.md` - The definitive SÃ©ance guide

---

### 3. Daily Rituals

#### Morning Review (Project Manager)

```markdown
**Daily Checklist:**
1. Check roadmap for ðŸŸ¢ items â†’ archive immediately
2. Review ðŸŸ¡ items for stalls (>2 days no movement)
3. Update CLAUDE.md Active Work section
4. Identify ðŸ”´ blocked items â†’ can blockers be resolved?
5. Prepare next batch if current batch near completion
```

#### Evening Handoff (All Agents)

Before ending session:
```markdown
1. Update task checkboxes in roadmap
2. Add implementation notes if work is mid-feature
3. Commit WIP with clear message if unable to complete
4. Update status:
   - Still working tomorrow? Keep ðŸŸ¡
   - Done but needs review? Mark ðŸŸ¢, notify PM
   - Hit blocker? Mark ðŸ”´, update "Blocked by:" field
```

---

### 4. Pattern Detection and Defeat

Haunt includes a **TDD-for-agent-behavior** system:

**Pattern Found â†’ Test Written â†’ Agent Trained â†’ Pattern Defeated**

Example anti-pattern: "Implementation summary in wrong location"

**Step 1: Pattern Found**
```
Agent created: Haunt/scripts/REQ-042-IMPLEMENTATION.md
Violates: .claude/rules/gco-file-conventions.md
  "Implementation summaries go to .haunt/completed/"
```

**Step 2: Test Written**
```python
# .haunt/tests/patterns/test_file_conventions.py
def test_implementation_summary_location():
    """Verify implementation summaries go to .haunt/completed/"""
    summaries = glob.glob("Haunt/scripts/*IMPLEMENTATION.md")
    assert len(summaries) == 0, \
        f"Found summaries in wrong location: {summaries}"
```

**Step 3: Agent Trained**
Update `.claude/rules/gco-file-conventions.md`:
```markdown
## Prohibitions

NEVER put implementation summaries in source directories:
- NEVER: Haunt/scripts/REQ-XXX-IMPLEMENTATION.md
- ALWAYS: .haunt/completed/REQ-XXX-implementation-summary.md
```

**Step 4: Pattern Defeated**
- Rule auto-loads in all future sessions
- Test runs in CI to catch violations
- Pattern cannot recur

---

## Getting Started

### Quick Installation (3 Commands)

```bash
# 1. Clone repository
git clone https://github.com/yourusername/haunt.git
cd haunt

# 2. Run setup
bash Haunt/scripts/setup-haunt.sh

# 3. Verify installation
bash Haunt/scripts/setup-haunt.sh --verify
```

**What setup does:**
- Copies agent character sheets to `~/.claude/agents/`
- Installs rules to `~/.claude/rules/` (auto-loaded)
- Creates project structure (`.haunt/plans/`, `.haunt/completed/`, etc.)
- Verifies prerequisites (Git, Python 3.11+, Node.js 18+)

---

### Your First Project

#### Step 1: Start with Project Manager

```bash
claude -a project-manager
```

```
You: "I want to build a REST API for managing book reviews.
     Users can register, log in, post reviews, and rate books."
```

**PM will:**
1. Confirm understanding
2. Generate formal requirements
3. Perform strategic analysis (JTBD, Kano, RICE scoring)
4. Create roadmap with sized requirements (S: 1-4h, M: 4-8h)
5. Assign agents to requirements

---

#### Step 2: Implement Features with Dev Agent

```bash
claude -a dev
```

Agent automatically:
- Runs session startup (verify tests, check git status)
- Finds assignment from roadmap
- Implements feature following TDD workflow
- Updates roadmap status (âšª â†’ ðŸŸ¡ â†’ ðŸŸ¢)
- Commits with proper format: `[REQ-XXX] Action: Description`

---

#### Step 3: Review with Code Reviewer

```bash
claude -a code-reviewer
```

Reviewer checks:
- All tests passing
- Code follows patterns (no detected anti-patterns)
- Commit messages follow convention
- Implementation matches requirement completion criteria

---

#### Step 4: Track Progress

Check `.haunt/plans/roadmap.md`:
```markdown
## Current Focus: Book Review API

**Active Work:**
- ðŸŸ¢ REQ-001: Database schema for users and reviews
- ðŸŸ¡ REQ-002: User authentication endpoints
- âšª REQ-003: Book review CRUD endpoints

**Recently Completed:**
- ðŸŸ¢ REQ-001: Database schema (2025-01-15)
```

PM archives completed work automatically, unblocking dependent requirements.

---

### First Session Success Criteria

You know setup succeeded when:
- âœ… `claude --list-agents` shows `gco-dev`, `gco-project-manager`, etc.
- âœ… Starting `claude -a dev` runs session startup automatically
- âœ… Agent creates commits in format: `[REQ-XXX] Action: Description`
- âœ… `.haunt/plans/roadmap.md` exists with requirement structure
- âœ… Tests pass before agent starts new work

---

## Implementation Details

### Roadmap-Driven Development

**File:** `.haunt/plans/roadmap.md`

**Purpose:** Single source of truth for all active work

**Structure:**
```markdown
## Current Focus: [Phase Name]

**Goal:** [One sentence goal]

**Active Work:**
- ðŸŸ¡ REQ-XXX: [Title] - [Brief status]

**Recently Completed:**
- ðŸŸ¢ REQ-XXX: [Title]

---

## Batch N: [Phase Name]

### ðŸŸ¡ REQ-XXX: [Action-oriented title]

**Type:** Enhancement | Bug Fix | Documentation | Research
**Reported:** YYYY-MM-DD
**Source:** User story | Bug report | Refactor

**Description:**
[What needs to be done and why]

**Tasks:**
- [x] Completed task
- [ ] Remaining task

**Files:**
- `path/to/file.py` (create | modify)

**Effort:** XS | S | M | SPLIT
**Complexity:** SIMPLE | MODERATE | COMPLEX | UNKNOWN
**Agent:** Dev-Backend | Dev-Frontend | Dev-Infrastructure
**Completion:** [Testable criteria]
**Blocked by:** REQ-XXX | None
```

---

### Commit Convention Enforcement

**Every commit follows:**
```
[REQ-XXX] Action: Brief description

What was done:
- Specific change 1
- Specific change 2

ðŸ¤– Generated with Claude Code
```

**Actions:**
- `Add` - New functionality or files
- `Update` - Enhance existing features
- `Fix` - Correct bugs
- `Remove` - Delete code or features
- `Refactor` - Restructure without changing behavior
- `Test` - Add or update tests
- `Docs` - Documentation changes

**Enforcement:**
- Rule file: `.claude/rules/gco-commit-conventions.md` (auto-loaded)
- Agents cannot commit without following format
- Pattern tests verify commit message quality
- Git hooks can validate commit format in CI

---

### Testing Philosophy

**Tests Before Code (Always)**

```markdown
# TDD Workflow (from gco-tdd-workflow skill)

## Red Phase
1. Understand requirement from roadmap
2. Write test that would pass if feature existed
3. Run test suite - verify new test FAILS
4. Commit: [REQ-XXX] Test: Add test for [feature]

## Green Phase
1. Implement simplest code to pass test
2. Run test suite - verify new test PASSES
3. Verify all existing tests still pass
4. Commit: [REQ-XXX] Add: Implement [feature]

## Refactor Phase
1. Clean up code (improve readability, remove duplication)
2. Run test suite - verify all tests still pass
3. Commit: [REQ-XXX] Refactor: Clean up [component]
```

**Test command enforcement:**
- Backend: `pytest tests/ -x -q`
- Frontend: `npm test`
- Infrastructure: `terraform plan`, `ansible --check`

**Session startup includes test verification** - broken tests MUST be fixed before starting new work.

---

### Agent Memory Integration

**MCP Agent Memory Server** (optional but recommended):

```bash
# Store significant decisions
store_memory(
  content="Chose PostgreSQL over MongoDB for ACID compliance requirements",
  category="dev-backend",
  tags=["architecture", "REQ-042", "database"]
)

# Recall context when resuming multi-session work
recall_context("dev-backend-REQ-042")
```

**When to use:**
- Multi-session features (>1 day of work)
- Complex architectural decisions
- Work resuming after >24 hour gap

**When to skip:**
- Single-session tasks
- Well-documented requirements
- Fresh features with no prior context

---

## Conclusion

### Summary of Benefits

**For Individual Developers:**
- âœ… AI agents that remember your project conventions across sessions
- âœ… Automated enforcement of testing standards and commit quality
- âœ… Roadmap-driven workflow prevents "what should I work on?" paralysis
- âœ… Pattern detection catches mistakes before they spread

**For Teams:**
- âœ… Consistent AI behavior across all team members
- âœ… Parallel agent execution (backend, frontend, infrastructure simultaneously)
- âœ… Clear dependency management prevents blocking issues
- âœ… Shared methodology scales tribal knowledge

**For Projects:**
- âœ… External memory system preserves architectural decisions
- âœ… Quality gates prevent technical debt accumulation
- âœ… Automated archival keeps roadmap clean and focused
- âœ… Strategic analysis (JTBD, Kano, RICE) ensures high-impact work

---

### The Vision: Autonomous AI Teams

Haunt's ultimate goal is **human-supervised AI autonomy**:

**Today:** Developer assigns work â†’ Agent implements â†’ Developer reviews
**Tomorrow:** PM agent triages issues â†’ Dispatches to appropriate agents â†’ Code Reviewer merges when ready â†’ Release Manager deploys

**Human role shifts from:**
- Writing every line of code â†’ Reviewing architectural decisions
- Manually tracking progress â†’ Approving batch completions
- Debugging failing tests â†’ Defining acceptance criteria

**AI agents handle:**
- Implementation details (code, tests, commits)
- Progress tracking (roadmap status updates)
- Quality enforcement (pattern detection, verification checklists)
- Coordination (dependency tracking, batch organization)

**The human remains the decision-maker** on:
- What to build (requirements approval)
- When to ship (release authorization)
- How to scale (architecture review)

Haunt provides the **scaffolding for AI teams to work autonomously while maintaining human oversight**.

---

### Next Steps

**Explore the Framework:**
1. Read `Haunt/README.md` - Architecture overview
2. Review `Haunt/SETUP-GUIDE.md` - Complete installation guide
3. Browse `Haunt/agents/` - Agent character sheets
4. Study `Haunt/skills/` - Reusable workflows

**Start Your First Project:**
1. Run setup: `bash Haunt/scripts/setup-haunt.sh`
2. Spawn PM: `claude -a project-manager`
3. Describe what you want to build
4. Watch as PM creates roadmap with sized requirements
5. Spawn Dev agent: `claude -a dev` to implement first requirement

**Join the Community:**
- Share your roadmap patterns
- Contribute skills for common workflows
- Report anti-patterns you've detected
- Help improve the methodology

**Haunt is not just a toolâ€”it's a methodology for building software with AI teammates who remember, coordinate, and deliver quality work session after session.**

### Key Takeaways

**What Haunt Is:**
- ðŸ§  External memory framework (rules, skills, agents) that gives stateless LLMs persistent knowledge
- ðŸ“‹ Roadmap-driven project management with dependency tracking and batch parallelization
- ðŸ”§ Specialized agent roles (Dev, PM, Research, Code Reviewer) with clear boundaries
- âœ… Quality enforcement through automated checklists, pattern detection, and verification gates

**What Haunt Provides:**
- **For developers**: AI agents that remember your conventions across sessions
- **For teams**: Parallel agent execution with consistent behavior
- **For projects**: Quality gates that prevent technical debt accumulation
- **For decisions**: Strategic analysis (JTBD, Kano, RICE) ensures high-impact work

**Core Philosophy:**
- Agents reference methodology, don't duplicate it (DRY for AI)
- Rules enforce invariants, skills provide workflows
- Roadmap is the communication layer between agents
- Human stays in control of what/when/how decisions

**Start in 3 commands:**
```bash
bash Haunt/scripts/setup-haunt.sh
claude -a project-manager  # Describe what you want to build
claude -a dev              # Implement first requirement
```

---

## Appendix: Quick Reference

### Common Commands

```bash
# Setup and verification
bash Haunt/scripts/setup-haunt.sh              # Full setup
bash Haunt/scripts/setup-haunt.sh --verify     # Verify installation
bash Haunt/scripts/setup-haunt.sh --agents-only # Update agents only

# Spawn agents
claude -a project-manager    # Roadmap coordination
claude -a dev                # Development (backend/frontend/infrastructure)
claude -a research           # Technical investigation
claude -a code-reviewer      # PR review
claude -a release-manager    # Release coordination

# Check status
cat .haunt/plans/roadmap.md  # View roadmap
git log --oneline -10        # Recent commits
ls .haunt/completed/         # Archived work
```

---

### Key File Locations

```
ghost-county/
â”œâ”€â”€ Haunt/                          # Framework source
â”‚   â”œâ”€â”€ agents/gco-*.md             # Agent character sheets
â”‚   â”œâ”€â”€ rules/gco-*.md              # Invariant enforcement
â”‚   â”œâ”€â”€ skills/gco-*/SKILL.md       # Reusable workflows
â”‚   â””â”€â”€ scripts/setup-haunt.sh      # Deployment script
â”œâ”€â”€ .haunt/                         # Haunt project artifacts
â”‚   â”œâ”€â”€ plans/roadmap.md            # Active requirements
â”‚   â”œâ”€â”€ completed/                  # Archived work
â”‚   â”œâ”€â”€ progress/                   # Session notes
â”‚   â””â”€â”€ tests/patterns/             # Pattern defeat tests
â””â”€â”€ CLAUDE.md                       # Project context (always loaded)
```

---

### Status Icon Reference

| Icon | Status | Agent Action |
|------|--------|--------------|
| âšª | Not Started | Pick up when ready, update to ðŸŸ¡ |
| ðŸŸ¡ | In Progress | Working on this, update tasks as complete |
| ðŸŸ¢ | Complete | All criteria met, notify PM for archival |
| ðŸ”´ | Blocked | Cannot proceed, waiting for dependency |

---

**Version:** Haunt v2.0
**Last Updated:** 2025-12-31
**License:** MIT
**Documentation:** `Haunt/README.md`, `Haunt/SETUP-GUIDE.md`, `Haunt/docs/SEANCE-EXPLAINED.md`
